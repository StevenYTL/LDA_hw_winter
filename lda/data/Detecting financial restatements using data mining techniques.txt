paragraph:1
Financial restatements have been a major concern for the regulators, investors and market participants. In the event of a material inaccuracy, firms need to revise their previously published financial statement(s) which is termed as financial restatements. There are two types of financial restatements: intentional (i.e. frauds) and unintentional (i.e. material errors in financial statements). Most of the data mining predictive models concentrate on fraudulent or intentional restatements for model building (e.g. Cecchini, Aytug, Koehler, & Pathak, 2010; Kim, Baik, & Cho, 2016) and unintentional restatements have received very little attention in the literature. However, focussing only on fraudulent cases has some practical shortcomings.

paragraph:2
First, many companies that manipulates earnings, remain undetected and the financial restatements are wrongly categorized as unintentional restatement (Dechow, Ge, Larson, & Sloan, 2011). Detected intentional/fraudulent restatements are relatively rare as compared to the unintentional cases. Our sample shows that unintentional restatements are almost 31 times (3404 unintentional restatement to 109 intentional/ fraudulent restatement) more prevalent than fraudulent (or intentional) restatements. While unintentional restatements are more common in general, this can also be attributed to the evolving nature of financial frauds and an increased level of sophistication to hide fraudulent activities. Therefore, exclusion of unintentional restatements from the sample, may lead to incomplete predictive models.

paragraph:3
Second, focussing primarily on fraudulent restatements may create a misleading perception that unintentional restatements are somewhat not detrimental for a firm and its investors. Earlier studies have shown that magnitude of the market reactions to large scale unintentional restatements are quite similar to that of fraudulent restatements and can erode investors’ confidence (Bowen, Dutta, & Zhu, 2017; Palmrose, Richardson, & Scholz, 2004). Therefore it is important for us to pay a close to the significant unintentional restatements as well. A lack of focus on unintentional restatements could lead to a more relaxed internal control environment and lessen the efforts for curbing managerial oversights and instances of misreporting.

paragraph:4
In order to address this research gap, we focus on developing predictive models based on both intentional (fraudulent) and unintentional (erroneous) financial restatements using a comprehensive real dataset that includes 3513 restatement cases over a period of 2001–2014. To the best of our knowledge it is the most comprehensive dataset used in the financial restatement predictive models. Our study also makes contributions to the datamining literature by (i) focussing on various datamining techniques and presenting a comparative analysis, (ii) ensuring the robustness of various predictive models over different time periods. The literature suggests that there is no consensus on the appropriate datamining techniques, primarily due to the evolving nature of restatement activities and changes in business environment. As Cecchini et al. (2010) suggest, “…future studies should take into account the fact that fraudsters will change their tactics to hide fraud” (Cecchini et al., 2010, p. 1158). It appears that effectiveness of any particular technique depends on the nature of dataset and different time periods. We address this concern in the following ways.

paragraph:5
First, we have employed all widely used data mining techniques in this area (Albashrawi, 2016; Ngai, Hu, Wong, Chen, & Sun, 2011), namely, Decision Tree (DT), Artificial Neural Network (ANN), Naïve Bayes (NB), Support Vector Machine (SVM), and Bayesian Belief Network (BBN) Classifier while developing the predictive models. This allows us to explore the most suitable data mining technique – leading to the best possible predictive model in a comprehensive dataset. In order to ensure the robustness of the predictive models, we have considered a comprehensive list of attributes (116 firm- and industry-specific attributes) while building our models.1 Subsequently, in order to develop more parsimonious models, we performed feature subset selection using stepwise forward selection to reduce less significant or redundant attributes. Our final dataset includes 15 attributes. Another challenge with a financial restatement study is the rarity of restatement events which result into class imbalance problem. In order to address this issue we use an oversample technique, namely Synthetic Minority Oversampling Technique (SMOTE), which increases the instances of minority class and leads to informational gain in the dataset. Our results show that Artificial Neural Network (ANN) leads to the best predictive model with an AUC value of 83%. Decision Tree (DT) and Bayesian Belief network (BBN) algorithms show a similar result while the application of Support Vector machine (SVM) and Naïve Bayes (NB) algorithm lead to weaker predictive models.

paragraph:6
Second, there is a concern that restatement activities evolve over time and hence we need to be careful about the stability of predictive models in different time periods. We use the recent financial crisis of 2008 as an external shock to the market and examine whether predictive models remain stable during pre- and post-crisis periods. The financial crisis has exposed a series of scandalous and unethical activities (e.g. subprime mortgage scandal, stock option manipulation, accounting restatements) undertaken by the executives of large U.S. firms. As a result, firms are subjected to more intense scrutiny in the post crisis period. Does a renewed focus on financial integrity have an impact on financial restatement predictive model? In order to address this concern, we develop predictive models for three different time periods: (i) full sample period (i.e. 2001–2014), (ii) pre-crisis period (i.e. till 2008), and (iii) post-crisis period (i.e. post 2008). Our results show consistent performance of various predictive models in different time periods.

paragraph:7
The data mining literature further suggests that data quality is quite important for developing reliable predictive models (Banarescu, 2015). We have taken a number of steps to ensure the integrity of data quality. First, we have considered a comprehensive list of restatement cases in developing our predictive models. Only a few studies have focussed on unintentional restatement cases while developing predictive models. However, it appears that number of restatement cases included in those studies are quite limited.2 Therefore, by employing a more comprehensive dataset on financial restatement in this study, we are able to present more reliable predictive models. Second, some of the restatement cases could be very trivial and may create ‘noise’ in predictive models. In order to eliminate the trivial restatement instances we retain only the “adverse effect” 3 cases, as identified in Audit Analytics databases. We also exclude the cases that involve clerical errors and are associated with accounting rule change.

paragraph:8
Third, it is also quite important to recognize that the choice of restatement data sources may significantly affect the validity of predictive models. Majority of the studies use U.S. GAO database. However, since this database mainly focusses on restatement announcement year and does not include the information on restatement periods, it is quite challenging to use this dataset to develop predictive models (Dechow et al., 2011). The other commonly used database, Accounting and Auditing Enforcement Releases (AAER) database, mainly includes intentional restatement cases. While this database is quite useful for developing predictive models for fraudulent cases, it is less effective for developing a more holistic model that focusses on all ‘adverse effect’ restatements. In order to overcome these challenges, we use Audit Analytics database that includes a comprehensive set of both intentional and unintentional restatement cases.

paragraph:9
Overall, the study makes the following contributions to the datamining literature: (i) unlike earlier studies that focusses only on financial frauds, we consider both intentional (fraud) and unintentional restatements in this study, (ii) we use the most comprehensive restatement dataset in developing our predictive models, (iii) we employ all widely used datamining techniques in this study and present a comparative performance analysis, and (iv) we examine the robustness of various predictive models over different time periods. We believe this study will benefit academics, regulators, policymakers and investors. In particular, regulators and policymakers can pay a close attention to the suspected firms and investors can take actions in advance to reduce their investment risks. The results can also help improving expert and intelligent systems by providing more insights on both intentional and unintentional financial restatements.

paragraph:10
In the following section, we review relevant literature. In Section 3, we present the research methodology. In Section 4, we describe different datasets and data pre-processing. Section 5 discusses various components of model building. We then present the results in Section 6. Section 7 concludes this paper.

end of line !

DOI:https://doi.org/10.1016/j.eswa.2017.08.030

Periodical:Expert Systems with Applications

Keywords:Data mining, Financial restatements, Decision tree (DT), Artificial neural network (ANN), Naïve Bayes (NB), Support vector machine (SVM), 

Title:Detecting financial restatements using data mining techniques

Abstract:Financial restatements have been a major concern for the regulators, investors and market participants. Most of the previous studies focus only on fraudulent (or intentional) restatements and the literature has largely ignored unintentional restatements. Earlier studies have shown that large scale unintentional restatements can be equally detrimental and may erode investors’ confidence. Therefore it is important for us to pay a close to the significant unintentional restatements as well. A lack of focus on unintentional restatements could lead to a more relaxed internal control environment and lessen the efforts for curbing managerial oversights and instances of misreporting. In order to address this research gap, we focus on developing predictive models based on both intentional (fraudulent) and unintentional (erroneous) financial restatements using a comprehensive real dataset that includes 3,513 restatement cases over a period of 2001 to 2014. To the best of our knowledge it is the most comprehensive dataset used in the financial restatement predictive models. Our study also makes contributions to the datamining literature by (i) focussing on various datamining techniques and presenting a comparative analysis, (ii) ensuring the robustness of various predictive models over different time periods. We have employed all widely used data mining techniques in this area, namely, Decision Tree (DT), Artificial Neural Network (ANN), Naïve Bayes (NB), Support Vector Machine (SVM), and Bayesian Belief Network (BBN) Classifier while developing the predictive models. We find that ANN outperforms other data mining algorithms in our empirical setup in terms of accuracy and area under the ROC curve. It is worth noting that our models remain consistent over the full sample period (2001-2014), pre-financial-crisis period (2001-2008), and post-financial-crisis period (2009-2014). We believe this study will benefit academics, regulators, policymakers and investors. In particular, regulators and policymakers can pay a close attention to the suspected firms and investors can take actions in advance to reduce their investment risks. The results can also help improving expert and intelligent systems by providing more insights on both intentional and unintentional financial restatements.